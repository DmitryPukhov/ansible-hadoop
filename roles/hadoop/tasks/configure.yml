---

#- name: remove 127.0.1.1 from /etc/hosts
#  sudo: yes
#  lineinfile:
#    dest=/etc/hosts
#    state=absent
#    regexp="^127\.0\.\d\.\d\s"
- name: Commenting a line using the regualr expressions in Ansible.
  sudo: yes
  replace:
    name: '/etc/hosts'
    regexp: '^(127\.0\.\d\.\d\s*\w*)$'
    replace: '#\1'


- name: set JAVA_HOME in .bashrc
  lineinfile:
    #dest: '{{ hadoop_user_home }}/.bashrc'
    dest: '/etc/bash.bashrc'
    line: 'export JAVA_HOME={{ java_home }}'
    regexp: '^(# *)?export JAVA_HOME='

- name: set HADOOP_HOME in .bashrc
  lineinfile:
    #dest: '{{ hadoop_user_home }}/.bashrc'
    dest: '/etc/bash.bashrc'
    line: 'export HADOOP_HOME={{ hadoop_home }}'
    regexp: '^(# *)?export HADOOP_HOME='

- name: set HADOOP_PREFIX in .bashrc
  lineinfile:
    #dest: '{{ hadoop_user_home }}/.bashrc'
    dest: '/etc/bash.bashrc'
    line: 'export HADOOP_PREFIX={{ hadoop_home }}'
    regexp: '^(# *)?export HADOOP_PREFIX='


- name: set HADOOP_CONF_DIR in .bashrc
  lineinfile:
    #dest: '{{ hadoop_user_home }}/.bashrc'
    dest: '/etc/bash.bashrc'
    line: 'export HADOOP_CONF_DIR={{ hadoop_home }}/conf'
    regexp: '^(# *)?export HADOOP_CONF_DIR='


- name: add PATH to HADOOP_HOME/bin in .bashrc
  lineinfile:
#    dest: '{{ hadoop_user_home }}/.bashrc'
    dest: '/etc/bash.bashrc'
    line: 'export PATH=$PATH:{{ hadoop_home }}/bin:{{ hadoop_home }}/sbin # HADOOP-BIN-PATH'
    regexp: '# HADOOP-BIN-PATH'


- name: Ensure hadoop/conf directory exists
  file:
    path: '{{hadoop_home}}/conf'
    state: directory
    owner: '{{ hadoop_user }}'
    group: '{{hadoop_group}}'


- name: Copy hadoop config files
  template:
    src: 'templates/hadoop/conf/{{ item }}'
    dest: '{{ hadoop_home }}/conf/{{ item }}'
    force: yes
    owner: '{{ hadoop_user }}'
    group: '{{ hadoop_group }}'
  with_items:
    - hadoop-env.sh
    - 'yarn-env.sh'
    - 'core-site.xml'
    - 'hdfs-site.xml'
    - 'yarn-site.xml'
    - 'core-site.xml'
    - 'capacity-scheduler.xml'
    - 'workers'
    - 'log4j.properties'

- name: delete old hdfs data
  file:
    path: '/home/{{ hadoop_user }}/data/hdfs'
    state: absent

- name: delete old tmp dir
  file:
    path: '{{ hadoop_tmp_dir }}'
    state: absent


- name: format namenode
  command: "{{ hadoop_home }}/bin/hdfs namenode -format -force -nonInteractive creates=/home/{{ hadoop_user }}/data/hdfs/namenode"


- name: chown to hadoop user
  file:
    dest: '/home/{{ hadoop_user }}/data'
    owner: '{{ hadoop_user }}'
    group: '{{ hadoop_group }}'
    recurse: yes
